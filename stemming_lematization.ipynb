{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef49f25c-b445-498d-bc10-caf576087bb7",
   "metadata": {},
   "source": [
    "## Stemming using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284356d-503e-4229-bbc2-b8fb9b6e105a",
   "metadata": {},
   "source": [
    "Stemming is a method in text processing that eliminates prefixes and suffixes from words, transforming them into their fundamental or root form, The main objective of stemming is to streamline and standardize words, enhancing the effectiveness of the natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e852ce1-c72c-4cae-8224-94cc8ece136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff8b38e-123e-48e8-91b6-d5248b72978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d0a26a-5cde-4f48-a3e7-52b687a15a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  ------>  eat\n",
      "eats  ------>  eat\n",
      "eat  ------>  eat\n",
      "ate  ------>  ate\n",
      "adjustable  ------>  adjust\n",
      "rafting  ------>  raft\n",
      "ability  ------>  abil\n",
      "meeting  ------>  meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word,\" ------> \",stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5776fa-5b1b-47ac-b4e9-684ff27ab04c",
   "metadata": {},
   "source": [
    "## Lemmatization in Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36155e-8298-4eb0-9445-f1b26a6730f3",
   "metadata": {},
   "source": [
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b42f3e84-995c-461c-b8ac-e7d6239f49f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  ---->  eat\n",
      "eats  ---->  eat\n",
      "eat  ---->  eat\n",
      "ate  ---->  eat\n",
      "adjustable  ---->  adjustable\n",
      "rafting  ---->  raft\n",
      "ability  ---->  ability\n",
      "meeting  ---->  meet\n",
      "better  ---->  well\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\n",
    "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" ----> \",token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4681f-ca87-4d15-b39f-4aada255793d",
   "metadata": {},
   "source": [
    "## Customizing lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b759c6bf-a0e6-490f-9d99-01f804f10972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4efce3-bbf9-4cc9-bc89-3c39703c9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  ---->  Bro\n",
      ",  ---->  ,\n",
      "you  ---->  you\n",
      "wanna  ---->  wanna\n",
      "go  ---->  go\n",
      "?  ---->  ?\n",
      "Brah  ---->  Brah\n",
      ",  ---->  ,\n",
      "do  ---->  do\n",
      "n't  ---->  not\n",
      "say  ---->  say\n",
      "no  ---->  no\n",
      "!  ---->  !\n",
      "I  ---->  I\n",
      "am  ---->  be\n",
      "exhausted  ---->  exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.text, \" ----> \", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea8bbf-a642-4c3d-a740-67d2ae86f16b",
   "metadata": {},
   "source": [
    "### attribute_ruler\n",
    "The attribute ruler lets you set token attributes for tokens identified by Matcher patterns. The attribute ruler is typically used to handle exceptions for token attributes and to map values between attributes such as mapping fine-grained POS tags to coarse-grained POS tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9ca18a-fea7-4615-977d-e0b114b4e95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  ---->  Brother\n",
      ",  ---->  ,\n",
      "you  ---->  you\n",
      "wanna  ---->  wanna\n",
      "go  ---->  go\n",
      "?  ---->  ?\n",
      "Brah  ---->  Brother\n",
      ",  ---->  ,\n",
      "do  ---->  do\n",
      "n't  ---->  not\n",
      "say  ---->  say\n",
      "no  ---->  no\n",
      "!  ---->  !\n",
      "I  ---->  I\n",
      "am  ---->  be\n",
      "exhausted  ---->  exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe(\"attribute_ruler\")\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.text, \" ----> \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27588248-38c3-4e57-8c23-eec0a38d7a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
